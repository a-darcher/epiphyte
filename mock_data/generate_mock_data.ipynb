{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import uniform\n",
    "import database.config as config\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Generate Spike Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 1\n",
    "session_nr = 1\n",
    "\n",
    "nr_units_patient_1 = 100\n",
    "begin_recording_time = 449860058\n",
    "stop_recording_time = 454664467\n",
    "\n",
    "unit_types = ['M', 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = []\n",
    "for i in range(nr_units_patient_1):\n",
    "    nr_spikes = int(uniform(10000, 16000))\n",
    "    spike_vec = []\n",
    "    for j in range(nr_spikes):\n",
    "        spike_vec.append(uniform(begin_recording_time, stop_recording_time))\n",
    "    spikes.append(spike_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range((nr_units_patient_1)):\n",
    "    np.save(\"{}/mock_data/spikes/{}/session_{}/CSC{}_{}UA{}.npy\".format(config.PATH_TO_REPO, patient_id, session_nr, i+1, random.choice(unit_types), '1'), spikes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 2\n",
    "session_nr = 1\n",
    "nr_units_patient_2 = 84 \n",
    "begin_recording_time = 449860058\n",
    "stop_recording_time = 454664467\n",
    "\n",
    "spikes = []\n",
    "for i in range(nr_units_patient_2):\n",
    "    nr_spikes = int(uniform(10000, 16000))\n",
    "    spike_vec = []\n",
    "    for j in range(nr_spikes):\n",
    "        spike_vec.append(uniform(begin_recording_time, stop_recording_time))\n",
    "    spikes.append(spike_vec)\n",
    "    \n",
    "for i in range((nr_units_patient_2)):\n",
    "    np.save(\"{}/mock_data/spikes/{}/session_{}/CSC{}_{}UA{}.npy\".format(config.PATH_TO_REPO, patient_id, session_nr, i+1, random.choice(unit_types), '1'), spikes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 3\n",
    "session_nr = 1\n",
    "nr_units_patient_3 = 59\n",
    "begin_recording_time = 449860058\n",
    "stop_recording_time = 454664467\n",
    "\n",
    "spikes = []\n",
    "for i in range(nr_units_patient_3):\n",
    "    nr_spikes = int(uniform(10000, 16000))\n",
    "    spike_vec = []\n",
    "    for j in range(nr_spikes):\n",
    "        spike_vec.append(uniform(begin_recording_time, stop_recording_time))\n",
    "    spikes.append(spike_vec)\n",
    "    \n",
    "for i in range((nr_units_patient_3)):\n",
    "    np.save(\"{}/mock_data/spikes/{}/session_{}/CSC{}_{}UA{}.npy\".format(config.PATH_TO_REPO, patient_id, session_nr, i+1, random.choice(unit_types), '1'), spikes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Create Channel Names File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# For patient 1\n",
    "brain_regions = [\"LA\", \"LAH\", 'LEC', \"LMH\", \"LPHC\", \"RA\", \"RAH\", \"REC\", \"RMH\", \"RPCH\"]\n",
    "nr_units_per_brain_region_1 = [7, 12, 9, 10, 15, 13, 8, 11, 12, 3]\n",
    "\n",
    "print(sum(nr_units_per_brain_region_1) == nr_units_patient_1)\n",
    "\n",
    "if os.path.exists(\"{}/mock_data/session_data/session_1_1_20190101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO)):\n",
    "    os.remove(\"{}/mock_data/session_data/session_1_1_20190101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO))\n",
    "    \n",
    "f1 = open(\"{}/mock_data/session_data/session_1_1_20190101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO), 'w+')\n",
    "for i in range(len(nr_units_per_brain_region_1)):\n",
    "    for j in range(nr_units_per_brain_region_1[i]):\n",
    "        f1.write(\"{}{}.ncs\\n\".format(brain_regions[i], j+1))\n",
    "        \n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for patient 2\n",
    "nr_units_per_brain_region_2 = [12, 9, 10, 5, 7, 11, 8, 7, 12, 3]\n",
    "\n",
    "if os.path.exists(\"{}/mock_data/session_data/session_2_1_20160101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO)):\n",
    "    os.remove(\"{}/mock_data/session_data/session_2_1_20160101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO))\n",
    "\n",
    "f2 = open(\"{}/mock_data/session_data/session_2_1_20160101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO), 'w+')\n",
    "for i in range(len(nr_units_per_brain_region_2)):\n",
    "    for j in range(nr_units_per_brain_region_2[i]):\n",
    "        f2.write(\"{}{}.ncs\\n\".format(brain_regions[i], j+1))\n",
    "        \n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for patient 3\n",
    "nr_units_per_brain_region_3 = [6, 5, 4, 6, 7, 10, 3, 7, 5, 6]\n",
    "sum(nr_units_per_brain_region_3)\n",
    "\n",
    "if os.path.exists(\"{}/mock_data/session_data/session_3_1_20170101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO)):\n",
    "    os.remove(\"{}/mock_data/session_data/session_3_1_20170101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO))\n",
    "\n",
    "f3 = open(\"{}/mock_data/session_data/session_3_1_20170101_12h00m00s/ChannelNames.txt\".format(config.PATH_TO_REPO), 'w+')\n",
    "for i in range(len(nr_units_per_brain_region_3)):\n",
    "    for j in range(nr_units_per_brain_region_3[i]):\n",
    "        f3.write(\"{}{}.ncs\\n\".format(brain_regions[i], j+1))\n",
    "        \n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Create Events File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_context_files = random.randint(100, 200) # generate length of events.nev & DAQ file. \n",
    "\n",
    "# recreate pings\n",
    "if len_context_files % 8 == 0:\n",
    "    reps = len_context_files / 8\n",
    "else:\n",
    "    reps = int(len_context_files / 8) + 1\n",
    "    \n",
    "signal_tile = np.tile([1,2,4,8,16,32,64,128], reps)\n",
    "signal_tile = signal_tile[:len_context_files]\n",
    "\n",
    "# recreate event timestamps\n",
    "events = np.linspace(begin_recording_time, stop_recording_time, num=len_context_files)\n",
    "\n",
    "events_mat = list(zip(events, signal_tile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Create DAQ File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Create Watch Log File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Create Stimulus Meta Data (here movie annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_movie_frames = 125725      # movie length: 5029 seconds (AVI file); 5029/0.04 = 125725\n",
    "perfect_pts = [round((x * 0.04), 2) for x in range(1, nr_movie_frames+1)]  \n",
    "\n",
    "annotator_ids = []\n",
    "for i in range(len(config.annotators)):\n",
    "    annotator_ids.append(config.annotators[i]['annotator_id'])\n",
    "\n",
    "path_to_movie_annotations = \"mock_data/movie_annotation\"\n",
    "\n",
    "nr_character_labels = 2\n",
    "\n",
    "start_times_1 = [0, 5000.04, 7000.04, 12000.04]\n",
    "stop_times_1 = [5000,7000,12000,12575]\n",
    "values_1 = [1,0,1,0]\n",
    "character1 = np.array([start_times_1, stop_times_1, values_1]) \n",
    "np.save(\"{}/{}/{}_character1_{}_20191212_character.npy\".format(\n",
    "    config.PATH_TO_REPO, path_to_movie_annotations, 1, random.choice(annotator_ids)), character1)\n",
    "\n",
    "\n",
    "start_times_2 = [0, 400.04, 4000.04, 10000.04, 10500.04]\n",
    "stop_times_2 = [400,4000,10000,10500,12575]\n",
    "values_2 = [0,1,0,1,0]\n",
    "character2 = np.array([start_times_2, stop_times_2, values_2]) \n",
    "np.save(\"{}/{}/{}_character2_{}_20191010_character.npy\".format(\n",
    "    config.PATH_TO_REPO, path_to_movie_annotations, 2, random.choice(annotator_ids)), character2)\n",
    "\n",
    "start_times_3 = [0, 100.04, 500.04]\n",
    "stop_times_3 = [100, 500, 12575]\n",
    "values_3 = [0,1,0]\n",
    "annot4 = np.array([start_times_3, stop_times_3, values_3]) \n",
    "np.save(\"{}/{}/{}_location1_{}_20200101_location.npy\".format(\n",
    "    config.PATH_TO_REPO, path_to_movie_annotations, 3, random.choice(annotator_ids)), annot4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
